{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業目標:\n",
    "    \n",
    "    建立一個網路模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業重點:\n",
    "\n",
    "請修改 Name 中, 自定義的 Layer 名稱\n",
    "\n",
    "增加一層全連階層\n",
    "\n",
    "宣告 MODEL API, 分別採用自行定義的 Input/Output Layer\n",
    "\n",
    "model.summary 查看 Layers stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "#主要輸入接收新聞標題本身，即一個整數序列（每個整數編碼一個詞）。\n",
    "#這些整數在1 到10,000 之間（10,000 個詞的詞彙表），且序列長度為100 個詞\n",
    "#宣告一個 NAME 去定義Input\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "\n",
    "# Embedding 層將輸入序列編碼為一個稠密向量的序列，\n",
    "# 每個向量維度為 512。\n",
    "x = Embedding(output_dim=512, input_dim=10000, input_length=100)(main_input)\n",
    "\n",
    "# LSTM 層把向量序列轉換成單個向量，\n",
    "# 它包含整個序列的上下文信息\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#插入輔助損失，使得即使在模型主損失很高的情況下，LSTM 層和Embedding 層都能被平穩地訓練\n",
    "news_output = Dense(1, activation='sigmoid', name='news_out')(lstm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#輔助輸入數據與LSTM 層的輸出連接起來，輸入到模型\n",
    "import keras\n",
    "news_input = Input(shape=(5,), name='news_in')\n",
    "x = keras.layers.concatenate([lstm_out, news_input])\n",
    "\n",
    "\n",
    "# 堆疊多個全連接網路層\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "#作業解答: 新增兩層\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu', name='new_layer')(x)\n",
    "\n",
    "# 最後添加主要的邏輯回歸層\n",
    "main_output = Dense(1, activation='sigmoid', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input=[main_input, news_input], outputs = [main_output, news_output])\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "                loss = {'main_output': 'binary_crossentropy',\n",
    "                'news_out': 'binary_crossentropy' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nmain_input (InputLayer)         (None, 100)          0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 100, 512)     5120000     main_input[0][0]                 \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 32)           69760       embedding_1[0][0]                \n__________________________________________________________________________________________________\nnews_in (InputLayer)            (None, 5)            0                                            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 37)           0           lstm_1[0][0]                     \n                                                                 news_in[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 64)           2432        concatenate_1[0][0]              \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 64)           4160        dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 64)           4160        dense_3[0][0]                    \n__________________________________________________________________________________________________\nnew_layer (Dense)               (None, 64)           4160        dense_4[0][0]                    \n__________________________________________________________________________________________________\nmain_output (Dense)             (None, 1)            65          new_layer[0][0]                  \n__________________________________________________________________________________________________\nnews_out (Dense)                (None, 1)            33          lstm_1[0][0]                     \n==================================================================================================\nTotal params: 5,208,930\nTrainable params: 5,208,930\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}